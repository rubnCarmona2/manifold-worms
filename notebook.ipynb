{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualModule(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super(ResidualModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(dims, dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.fc1(x)\n",
    "        x_1 = F.relu(x_1)\n",
    "        x = x + x_1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, task_dims, env_dims):\n",
    "        super(Agent, self).__init__()\n",
    "        self.processor = ResidualModule(task_dims)\n",
    "        self.head_pos = nn.Parameter(torch.randn(1, env_dims), requires_grad=True)\n",
    "        self.tail_pos = nn.Parameter(torch.randn(1, env_dims), requires_grad=True)\n",
    "        with torch.no_grad():\n",
    "            self.normalize_positions()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.processor(x)\n",
    "        return x\n",
    "\n",
    "    def normalize_positions(self):\n",
    "        self.head_pos.data = self.head_pos.data / self.head_pos.data.norm(2)\n",
    "        self.tail_pos.data = self.tail_pos.data / self.tail_pos.data.norm(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManifoldWorms(nn.Module):\n",
    "    def __init__(self, task_dims: int, env_dims: int, n_modules: int, reach: float = 1, garbage_decay: float = 0.9):\n",
    "        super(ManifoldWorms, self).__init__()\n",
    "        self.agents = nn.ModuleList([ResidualModule(task_dims) for _ in range(n_modules)])\n",
    "        self.head_positions = nn.Parameter(torch.randn(n_modules + 1, env_dims), requires_grad=True)\n",
    "        self.tail_positions = nn.Parameter(torch.randn(env_dims, n_modules + 1), requires_grad=True)\n",
    "        self.state = torch.zeros(1, n_modules + 1, task_dims).requires_grad_(False)\n",
    "        self.reach_threshold = np.clip(1 - reach, -1, 1).item()\n",
    "        self.garbage_scale = np.clip(1 - garbage_decay, 0, 1).item()\n",
    "        with torch.no_grad():\n",
    "            self.positions_normalization()\n",
    "\n",
    "    def forward(self, x: Optional[torch.Tensor] = None):\n",
    "        if x is not None:\n",
    "            self.state[:, -1] = self.state[:, -1] + x\n",
    "        self.step()\n",
    "    \n",
    "    def step(self):\n",
    "        self.positions_normalization()\n",
    "        # Calculate similarity matrix between all heads and tails\n",
    "        similarities = self.positions_similarity().unsqueeze(0).repeat(self.state.shape[0], 1, 1)  # [B, H, T]\n",
    "        # Create mask for valid interactions (heads close enough to tails)\n",
    "        closeness_mask = (similarities > self.reach_threshold).float()  # [B, H, T]\n",
    "        closeness_mask[:, -1] = 0 # No state should be sent to the entrance head\n",
    "        # Apply softmax across TAILS for each HEAD (dim=2)\n",
    "        influence = similarities * closeness_mask\n",
    "        influence = influence.masked_fill(closeness_mask == 0, float('-inf'))  # Mask out unreachable tails\n",
    "        influence = F.softmax(influence, dim=2).nan_to_num(0)  # Normalize over tails per head\n",
    "        influence = influence * closeness_mask  # Re-apply mask to ensure hard cutoff\n",
    "        # Calculate resources consumed FROM TAILS via heads\n",
    "        consumed_resources = influence.bmm(self.state)  # [B, H, D]\n",
    "        # Process only agent heads (exclude entrance head at last index)\n",
    "        tail_outputs = torch.stack([\n",
    "            self.agents[i](consumed_resources[:, i]) \n",
    "            for i in range(len(self.agents))  # Process n_modules agents\n",
    "        ], dim=1)  # [B, M, D]\n",
    "        tail_outputs = F.pad(tail_outputs, (0, 0, 0, 1))\n",
    "        # Calculate exit output (resources sent to exit tail)\n",
    "        exit_influence = influence[..., -1].unsqueeze(1)\n",
    "        exited_resources = exit_influence.bmm(tail_outputs)\n",
    "        # Calculate garbage (resources not consumed by any head)\n",
    "        garbage = (1 - closeness_mask).bmm(self.state)  # [B, T, D]\n",
    "        # Update state: remove consumed + add new deposits - exit outputs\n",
    "        state = (\n",
    "            self.state\n",
    "            - garbage * self.garbage_scale\n",
    "            - consumed_resources\n",
    "            + tail_outputs\n",
    "            - exited_resources\n",
    "        )\n",
    "        # Return the resources that exited and the garbage\n",
    "        return state, exited_resources, garbage\n",
    "\n",
    "    def positions_normalization(self):\n",
    "        self.head_positions.data = self.head_positions.data / self.head_positions.data.norm(2, dim=1, keepdim=True)\n",
    "        self.tail_positions.data = self.tail_positions.data / self.tail_positions.data.norm(2, dim=0, keepdim=True)\n",
    "\n",
    "    def positions_similarity(self):\n",
    "        dot_products = self.head_positions.mm(self.tail_positions)\n",
    "        l2_norms = self.head_positions.norm(2, dim=1, keepdim=True).mm(self.tail_positions.norm(2, dim=0, keepdim=True))\n",
    "        return dot_products / l2_norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ManifoldWorms(3, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0793, 0.8151, 0.9445],\n",
       "         [0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(4)[0].unsqueeze(0).unsqueeze(-1) * torch.rand(1, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [1, 5].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[375], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[373], line 40\u001b[0m, in \u001b[0;36mManifoldWorms.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate exit output (resources sent to exit tail)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m exit_influence \u001b[38;5;241m=\u001b[39m influence[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m exited_resources \u001b[38;5;241m=\u001b[39m \u001b[43mexit_influence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtail_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate garbage (resources not consumed by any head)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m garbage \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m closeness_mask)\u001b[38;5;241m.\u001b[39mbmm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)  \u001b[38;5;66;03m# [B, T, D]\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [1, 5]."
     ]
    }
   ],
   "source": [
    "test.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(test.state).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.step().unsqueeze(0).bmm(torch.ones(1, 5, 3))[:, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9843,  0.9439,  0.1510,  0.1296, -0.2182, -0.4939,  0.6764,  0.5787,\n",
       "         0.9008, -0.0981,  0.7976, -0.7385, -0.7170, -0.5712, -0.1985,  0.9126,\n",
       "        -0.9782,  0.0468, -0.1596,  0.4491, -0.8559,  0.5801,  0.6917,  0.1287,\n",
       "         0.4573], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.positions_similarity()[torch.where(test.positions_similarity())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, 0.9439, 0.0000, 0.0000, -0.0000],\n",
       "        [-0.0000, 0.6764, 0.5787, 0.9008, -0.0000],\n",
       "        [0.7976, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [0.9126, -0.0000, 0.0000, -0.0000, 0.4491],\n",
       "        [-0.0000, 0.5801, 0.6917, 0.0000, 0.4573]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.positions_similarity() * torch.where(test.positions_similarity() > 0.2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1297, 0.1297, 0.2879, 0.3230, 0.1297], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(test.positions_similarity() * torch.where(test.positions_similarity() > 0.2, 1, 0), 0)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.2826,  0.0839, -0.5363,  0.3267,  0.1196, -0.0198,  0.6452,  0.1791,\n",
       "          -0.1621,  0.1716]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0271, -0.0178, -0.2622,  0.3032,  0.7373,  0.2175,  0.2847, -0.1851,\n",
       "           0.1871,  0.3117]], requires_grad=True))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Agent(10, 10)\n",
    "a.head_pos, a.tail_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self, env_dims):\n",
    "        self.entrance__pos = torch.eye(env_dims)[0]\n",
    "        self.exit__pos = torch.eye(env_dims)[0] * -1\n",
    "        # Measures the distance between agents' tails\n",
    "        # \n",
    "        # For each agent\n",
    "        #   aggregate the outputs of all agents and weight by the distance to the agent\n",
    "        #   return the new position of the agent\n",
    "        pass\n",
    "\n",
    "    def normalize_positions(self, directory: Optional[Type[Agent]] = None):\n",
    "        if directory is None:\n",
    "            directory = self\n",
    "        position_vars = [var_name for var_name in dir(directory) if var_name.endswith('__pos')]\n",
    "        for var_name in position_vars:\n",
    "            var = getattr(directory, var_name)\n",
    "            var = var / torch.norm(var, 2)\n",
    "            setattr(directory, var_name, var)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
